% === Text-to-Audio Generation ===

@article{tangoflux2024,
  author    = {Hung, Chia-Yu and Majumder, Navonil and Kong, Zhifeng and Mehrish, Ambuj and Zadeh, Amir and Li, Chuan and Valle, Rafael and Catanzaro, Bryan and Poria, Soujanya},
  title     = {{TangoFlux}: Super Fast and Faithful Text to Audio Generation with Flow Matching and {CLAP}-Ranked Preference Optimization},
  journal   = {arXiv preprint arXiv:2412.21037},
  year      = {2024},
  note      = {Accepted at ICLR 2026},
}

@article{tango2023,
  author    = {Ghosal, Deepanway and Majumder, Navonil and Mehrish, Ambuj and Poria, Soujanya},
  title     = {Text-to-Audio Generation using Instruction-Tuned {LLM} and Latent Diffusion Model},
  journal   = {arXiv preprint arXiv:2304.13731},
  year      = {2023},
}

@inproceedings{audioldm2023,
  author    = {Liu, Haohe and Chen, Zehua and Yuan, Yi and Mei, Xinhao and Liu, Xubo and Mandic, Danilo and Wang, Wenwu and Plumbley, Mark D.},
  title     = {{AudioLDM}: Text-to-Audio Generation with Latent Diffusion Models},
  booktitle = {Proc. ICML},
  year      = {2023},
}

@article{audioldm22023,
  author    = {Liu, Haohe and Yuan, Yi and Liu, Xubo and Mei, Xinhao and Kong, Qiuqiang and Tian, Qiao and Wang, Yuping and Plumbley, Mark and Wang, Wenwu},
  title     = {{AudioLDM 2}: Learning Holistic Audio Generation with Self-supervised Pretraining},
  journal   = {arXiv preprint arXiv:2308.05734},
  year      = {2023},
}

@article{makeanaudio2023,
  author    = {Huang, Rongjie and Huang, Jiawei and Yang, Dongchao and Ren, Yi and others},
  title     = {{Make-An-Audio}: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models},
  journal   = {arXiv preprint arXiv:2301.12661},
  year      = {2023},
}

@inproceedings{audiogen2023,
  author    = {Kreuk, Felix and Synnaeve, Gabriel and Polyak, Adam and Singer, Uriel and Defossez, Alexandre and Copet, Jade and Parikh, Devi and Taigman, Yaniv and Adi, Yossi},
  title     = {{AudioGen}: Textually Guided Audio Generation},
  booktitle = {Proc. ICLR},
  year      = {2023},
}

@inproceedings{musicgen2023,
  author    = {Copet, Jade and Kreuk, Felix and Gat, Itai and others},
  title     = {Simple and Controllable Music Generation},
  booktitle = {Proc. NeurIPS},
  year      = {2023},
}

@article{stableaudio2024,
  author    = {Evans, Zach and Parker, Julian D. and Carr, CJ and Zukowski, Zack and Taylor, Josiah and Pons, Jordi},
  title     = {Stable Audio Open},
  journal   = {arXiv preprint arXiv:2407.14358},
  year      = {2024},
}

@article{ezaudio2024,
  author    = {Hai, Jiarui and Yang, Yong and Zhang, Jiatong and Lu, Jionghao and Wang, Changli},
  title     = {{EzAudio}: Enhancing Text-to-Audio Generation with Efficient Diffusion Transformer},
  journal   = {arXiv preprint arXiv:2409.10819},
  year      = {2024},
}

@article{genau2024,
  author    = {Haji-Ali, Mohamed and Hedge, Apoorv and St{\"o}ter, Fabian-Robert and others},
  title     = {Taming Data and Transformers for Audio Generation},
  journal   = {arXiv preprint arXiv:2406.19388},
  year      = {2024},
}

% === Diffusion/Flow Matching Architecture ===

@article{esser2024sd3,
  author    = {Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and others},
  title     = {Scaling Rectified Flow Transformers for High-Resolution Image Synthesis},
  journal   = {Proc. ICML},
  year      = {2024},
}

@inproceedings{peebles2023dit,
  author    = {Peebles, William and Xie, Saining},
  title     = {Scalable Diffusion Models with Transformers},
  booktitle = {Proc. ICCV},
  year      = {2023},
}

@inproceedings{ho2020ddpm,
  author    = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  title     = {Denoising Diffusion Probabilistic Models},
  booktitle = {Proc. NeurIPS},
  year      = {2020},
}

@inproceedings{rombach2022ldm,
  author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  title     = {High-Resolution Image Synthesis with Latent Diffusion Models},
  booktitle = {Proc. CVPR},
  year      = {2022},
}

@inproceedings{song2021ddim,
  author    = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  title     = {Denoising Diffusion Implicit Models},
  booktitle = {Proc. ICLR},
  year      = {2021},
}

@inproceedings{karras2022edm,
  author    = {Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  title     = {Elucidating the Design Space of Diffusion-Based Generative Models},
  booktitle = {Proc. NeurIPS},
  year      = {2022},
}

% === Flow Matching ===

@inproceedings{lipman2023flow,
  author    = {Lipman, Yaron and Chen, Ricky T. Q. and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matthew},
  title     = {Flow Matching for Generative Modeling},
  booktitle = {Proc. ICLR},
  year      = {2023},
}

@inproceedings{liu2023rectifiedflow,
  author    = {Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  title     = {Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},
  booktitle = {Proc. ICLR (Spotlight)},
  year      = {2023},
}

% === RoPE ===

@article{su2024roformer,
  author    = {Su, Jianlin and Lu, Yu and Pan, Shengfeng and Murtadha, Ahmed and Wen, Bo and Liu, Yunfeng},
  title     = {{RoFormer}: Enhanced Transformer with Rotary Position Embedding},
  journal   = {Neurocomputing},
  year      = {2024},
}

% === CoreML / Apple ===

@misc{apple2022ane,
  author    = {{Apple Machine Learning Research}},
  title     = {Deploying Transformers on the {Apple Neural Engine}},
  year      = {2022},
  howpublished = {\url{https://machinelearning.apple.com/research/neural-engine-transformers}},
}

@misc{apple2022sd,
  author    = {{Apple Machine Learning Research}},
  title     = {Stable Diffusion with {Core ML} on {Apple Silicon}},
  year      = {2022},
  howpublished = {\url{https://github.com/apple/ml-stable-diffusion}},
}

@misc{apple2024coreml,
  author    = {{Apple}},
  title     = {Deploy Machine Learning and {AI} Models On-device with {Core ML} --- {WWDC} 2024},
  year      = {2024},
  howpublished = {Session 10161},
}

% === Distillation / Acceleration ===

@inproceedings{song2023consistency,
  author    = {Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
  title     = {Consistency Models},
  booktitle = {Proc. ICML},
  year      = {2023},
}

@article{luo2023lcm,
  author    = {Luo, Simian and Tan, Yiqin and Huang, Longbo and Li, Jian and Zhao, Hang},
  title     = {Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference},
  journal   = {arXiv preprint arXiv:2310.04378},
  year      = {2023},
}

@inproceedings{salimans2022progressive,
  author    = {Salimans, Tim and Ho, Jonathan},
  title     = {Progressive Distillation for Fast Sampling of Diffusion Models},
  booktitle = {Proc. ICLR},
  year      = {2022},
}

@inproceedings{soundctm2024,
  author    = {Saito, Koichi and Kim, Dongjun and Shibuya, Takashi and Lai, Chieh-Hsin and Zhong, Zhi and Takida, Yuhta and Mitsufuji, Yuki},
  title     = {{SoundCTM}: Unifying Score-based and Consistency Models for Text-to-Sound Generation},
  booktitle = {Proc. ICLR},
  year      = {2025},
}

@article{flashaudio2024,
  author    = {Zhu, Huadai and others},
  title     = {{FlashAudio}: Rectified Flows for Fast and High-Fidelity Text-to-Audio Generation},
  journal   = {Proc. ACL},
  year      = {2025},
  note      = {arXiv:2410.12266},
}

% === Transformer / Foundation ===

@inproceedings{vaswani2017attention,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and others},
  title     = {Attention Is All You Need},
  booktitle = {Proc. NeurIPS},
  year      = {2017},
}

% === Audio Codec ===

@article{encodec2022,
  author    = {D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  title     = {High Fidelity Neural Audio Compression},
  journal   = {arXiv preprint arXiv:2210.13438},
  year      = {2022},
}

% === CLAP ===

@inproceedings{clap2023,
  author    = {Elizalde, Benjamin and Deshmukh, Soham and Al Ismail, Mahmoud and Wang, Huaming},
  title     = {{CLAP}: Learning Audio Concepts From Natural Language Supervision},
  booktitle = {Proc. ICASSP},
  year      = {2023},
}

% === Real-time Audio ===

@article{rave2021,
  author    = {Caillon, Antoine and Esling, Philippe},
  title     = {{RAVE}: A Variational Autoencoder for Fast and High-Quality Neural Audio Synthesis},
  journal   = {arXiv preprint arXiv:2111.05011},
  year      = {2021},
}

% === Sentence Embeddings ===

@inproceedings{reimers2019sentencebert,
  author    = {Reimers, Nils and Gurevych, Iryna},
  title     = {Sentence-{BERT}: Sentence Embeddings using Siamese {BERT}-Networks},
  booktitle = {Proc. EMNLP},
  year      = {2019},
}

% === SoundStorm ===

@article{soundstorm2023,
  author    = {Borsos, Zal{\'a}n and Sharifi, Matt and Vincent, Damien and Kharitonov, Eugene and Zeghidour, Neil and Tagliasacchi, Marco},
  title     = {{SoundStorm}: Efficient Parallel Audio Generation},
  journal   = {arXiv preprint arXiv:2305.09636},
  year      = {2023},
}
